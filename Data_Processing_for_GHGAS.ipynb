{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "mount_file_id": "1YC-q07k9RXOK2cdhXtzs3HFZF3O6iJlj",
      "authorship_tag": "ABX9TyOUeSaenTJOYfay40pB7v6M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jahidurmahim/GHG-CO2-Agrifood-prediction/blob/main/Data_Processing_for_GHGAS.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93dbf9bc"
      },
      "source": [
        "### **Import Libraries**\n",
        "This cell imports the necessary Python libraries for data manipulation, visualization, and numerical operations."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbad2926"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ce41667"
      },
      "source": [
        "### **Load Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5a7b44dd"
      },
      "source": [
        "df=pd.read_csv('/content/drive/MyDrive/FAO_GreenHouseGasEmission.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e2141c9"
      },
      "source": [
        "### **Display First Rows**\n",
        "This cell displays the first 5 rows of the DataFrame `df` to get a quick overview of the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ad177a0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "45491ec2"
      },
      "source": [
        "### **Check DataFrame Shape**\n",
        "This cell prints the number of rows and columns in the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ef3b119"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7d2e9dc"
      },
      "source": [
        "### **Display DataFrame Information**\n",
        "This cell provides a summary of the DataFrame, including column names, non-null counts, and data types, to identify potential issues like missing values or incorrect data types."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65b20eb4"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7a2e1c"
      },
      "source": [
        "### **Check for Missing Values**\n",
        "This cell calculates and displays the count of missing values for each column in the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "58f12fda"
      },
      "source": [
        "df.isna().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7574fa47"
      },
      "source": [
        "### **Check for Duplicate Rows**\n",
        "This cell counts and displays the number of duplicate rows in the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c6cb022"
      },
      "source": [
        "df.duplicated().sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6284505"
      },
      "source": [
        "### **Print Column Names**\n",
        "This cell prints all column names in the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82c52bb2"
      },
      "source": [
        "print(df.columns)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e44be1c9"
      },
      "source": [
        "### **Descriptive Statistics of Numeric Features**\n",
        "This cell generates descriptive statistics (count, mean, std, min, 25%, 50%, 75%, max) for all numeric columns in the DataFrame `df`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fd31c2b"
      },
      "source": [
        "df.describe().T"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dd009809"
      },
      "source": [
        "### **Outlier Detection using IQR Method**\n",
        "This cell identifies outliers in numeric columns using the Interquartile Range (IQR) method and summarizes the findings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d3240c3"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "outlier_summary = []\n",
        "\n",
        "numeric_cols = df.select_dtypes(include='number').columns\n",
        "\n",
        "for col in numeric_cols:\n",
        "    Q1 = df[col].quantile(0.25)\n",
        "    Q3 = df[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "    lower = Q1 - 1.5 * IQR\n",
        "    upper = Q3 + 1.5 * IQR\n",
        "\n",
        "    outliers = df[(df[col] < lower) | (df[col] > upper)][col].values\n",
        "    outlier_count = len(outliers)\n",
        "\n",
        "    if outlier_count > 0:\n",
        "        outlier_summary.append({\n",
        "            'feature': col,\n",
        "            'Q1': Q1,\n",
        "            'Q3': Q3,\n",
        "            'lower_bound': lower,\n",
        "            'upper_bound': upper,\n",
        "            'outlier_count': outlier_count,\n",
        "            'outlier_values': outliers\n",
        "        })\n",
        "\n",
        "outlier_df = pd.DataFrame(outlier_summary)\n",
        "outlier_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73090314"
      },
      "source": [
        "### **Visualize Numeric Feature Distributions and Outliers**\n",
        "This cell generates box plots for all numeric features to visually inspect their distributions and identify outliers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a9b09f2"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import math\n",
        "\n",
        "numeric_df = df.select_dtypes(include=['number'])\n",
        "\n",
        "columns_to_plot = []\n",
        "for col in numeric_df.columns:\n",
        "    if col == 'COMMENT_OBS' and df[col].isnull().all():\n",
        "        continue\n",
        "    if df[col].nunique() > 1:\n",
        "        columns_to_plot.append(col)\n",
        "\n",
        "\n",
        "if not columns_to_plot:\n",
        "    print(\"No suitable numeric columns found for boxplot visualization.\")\n",
        "else:\n",
        "    num_features = len(columns_to_plot)\n",
        "    num_cols = 3\n",
        "    num_rows = math.ceil(num_features / num_cols)\n",
        "\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=(num_cols * 5, num_rows * 4))\n",
        "    axes = axes.flatten()\n",
        "\n",
        "    for i, col in enumerate(columns_to_plot):\n",
        "        sns.boxplot(y=df[col], ax=axes[i])\n",
        "        axes[i].set_title(col)\n",
        "        axes[i].set_ylabel('')\n",
        "\n",
        "    for j in range(i + 1, len(axes)):\n",
        "        fig.delaxes(axes[j])\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.suptitle('Distribution and Outliers of Numeric Features', y=1.02, fontsize=16)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "912ec169"
      },
      "source": [
        "### **Outlier Capping**\n",
        "This cell applies outlier capping to the numeric columns in the DataFrame `df_capped` using the IQR method, limiting values to within 1.5 times the IQR from the quartiles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa357388"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "df_capped = df.copy()\n",
        "\n",
        "numeric_cols_for_capping = df_capped.select_dtypes(include=np.number).columns\n",
        "\n",
        "print(\"Applying outlier capping to the following numeric columns:\")\n",
        "for col in numeric_cols_for_capping:\n",
        "    if col == 'COMMENT_OBS':\n",
        "        continue\n",
        "\n",
        "    Q1 = df_capped[col].quantile(0.25)\n",
        "    Q3 = df_capped[col].quantile(0.75)\n",
        "    IQR = Q3 - Q1\n",
        "\n",
        "    lower_bound = Q1 - 1.5 * IQR\n",
        "    upper_bound = Q3 + 1.5 * IQR\n",
        "\n",
        "    df_capped[col] = df_capped[col].clip(lower=lower_bound, upper=upper_bound)\n",
        "    print(f\"- {col}: Outliers capped between {lower_bound:.2f} and {upper_bound:.2f}\")\n",
        "\n",
        "print(\"\\nOutlier capping process completed for all numeric columns.\")\n",
        "print(\"\\nHead of DataFrame after outlier capping (df_capped):\")\n",
        "display(df_capped.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "451aa064"
      },
      "source": [
        "### **Verify Outlier Capping for TIME_PERIOD**\n",
        "This cell displays descriptive statistics for the 'TIME_PERIOD' column after outlier capping to verify the changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dae6afcd"
      },
      "source": [
        "display(df_capped['TIME_PERIOD'].describe().T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "56d7eec5"
      },
      "source": [
        "### **Verify Outlier Capping for OBS_VALUE**\n",
        "This cell displays descriptive statistics for the 'OBS_VALUE' column after outlier capping to verify the changes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11997917"
      },
      "source": [
        "display(df_capped['OBS_VALUE'].describe().T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d62d3263"
      },
      "source": [
        "### **Drop Unnecessary Columns**\n",
        "This cell drops a predefined list of columns that are not considered relevant for further analysis from the DataFrame `df_cleaned`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08cdc52a"
      },
      "source": [
        "columns_to_drop = [\n",
        "    'STRUCTURE', 'STRUCTURE_ID', 'ACTION', 'FREQ', 'REF_AREA',\n",
        "    'INDICATOR', 'SEX', 'AGE', 'URBANISATION', 'UNIT_MEASURE',\n",
        "    'COMP_BREAKDOWN_1', 'COMP_BREAKDOWN_2', 'COMP_BREAKDOWN_3',\n",
        "    'DATABASE_ID', 'UNIT_MULT', 'UNIT_TYPE', 'TIME_FORMAT',\n",
        "    'OBS_STATUS', 'OBS_CONF',\n",
        "    'FREQ_LABEL',\n",
        "    'Breakdown_1', 'Breakdown_2', 'Breakdown_3'\n",
        "]\n",
        "\n",
        "df_cleaned = df_renamed.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "print(\"DataFrame columns after dropping unnecessary columns:\")\n",
        "print(df_cleaned.columns.tolist())\n",
        "\n",
        "print(\"\\nFirst 5 rows of the cleaned DataFrame:\")\n",
        "display(df_cleaned.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11fba096"
      },
      "source": [
        "### **Rename Columns for Clarity**\n",
        "This cell renames several columns in `df_cleaned` to more descriptive and user-friendly names, creating `df_final`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a334f200"
      },
      "source": [
        "final_rename_mapping = {\n",
        "    'Unit_Multiplier': 'Unit_Mult',\n",
        "    'Observation_Status': 'Obs_Status',\n",
        "    'Observation_Confidence': 'Obs_Conf'\n",
        "}\n",
        "\n",
        "df_final = df_cleaned.rename(columns=final_rename_mapping)\n",
        "\n",
        "print(\"Final DataFrame columns after further renaming:\")\n",
        "print(df_final.columns.tolist())\n",
        "\n",
        "print(\"\\nFirst 5 rows of the final cleaned and renamed DataFrame:\")\n",
        "display(df_final.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61566733"
      },
      "source": [
        "### **Min-Max Normalization**\n",
        "This cell applies Min-Max normalization to selected numeric columns in a copy of the DataFrame (`df_normalized`), scaling values to a range between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ba826a4f"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "df_normalized = df_capped.copy()\n",
        "\n",
        "numeric_cols_to_normalize = [\n",
        "    col for col in df_normalized.select_dtypes(include=['number']).columns\n",
        "    if df_normalized[col].nunique() > 1 and col not in ['UNIT_MULT', 'TIME_FORMAT']\n",
        "]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "df_normalized[numeric_cols_to_normalize] = scaler.fit_transform(df_normalized[numeric_cols_to_normalize])\n",
        "\n",
        "print(\"DataFrame after Min-Max normalization:\")\n",
        "display(df_normalized.head())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9013152b"
      },
      "source": [
        "### **Standardization (Z-score Scaling)**\n",
        "This cell applies standardization (Z-score scaling) to selected numeric columns in a copy of the DataFrame (`df_standardized`), transforming data to have a mean of 0 and a standard deviation of 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8a85039"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "df_standardized = df_final.copy()\n",
        "\n",
        "numeric_cols_to_standardize = [\n",
        "    col for col in df_standardized.select_dtypes(include=['number']).columns\n",
        "    if df_standardized[col].nunique() > 1 and col not in ['Unit_Mult', 'Time_Format']\n",
        "]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "df_standardized[numeric_cols_to_standardize] = scaler.fit_transform(df_standardized[numeric_cols_to_standardize])\n",
        "\n",
        "print(\"DataFrame after Standardization:\")\n",
        "display(df_standardized.head())"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}